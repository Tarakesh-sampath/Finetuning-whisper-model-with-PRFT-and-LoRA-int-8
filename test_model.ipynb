{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "import transformers\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "import transformers\n",
    "from scipy.signal import resample\n",
    "\n",
    "class LiveTranscriber:\n",
    "    def __init__(self, model_name=\"openai/whisper-small\", device=None):\n",
    "        \"\"\"\n",
    "        Initialize the live transcription system.\n",
    "        \n",
    "        :param model_name: Hugging Face model for transcription\n",
    "        :param device: Compute device (cuda/cpu)\n",
    "        \"\"\"\n",
    "        # Determine optimal device and dtype\n",
    "        if device is None:\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "        # Explicitly use float32 to avoid type conversion issues\n",
    "        self.torch_dtype = torch.float32\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "        print(f\"Using dtype: {self.torch_dtype}\")\n",
    "        \n",
    "        # Load Whisper model and processor\n",
    "        self.processor = transformers.WhisperProcessor.from_pretrained(model_name)\n",
    "        self.model = transformers.WhisperForConditionalGeneration.from_pretrained(\n",
    "            model_name, \n",
    "            torch_dtype=self.torch_dtype\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Ensure model is in evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Audio stream configurations\n",
    "        self.target_sample_rate = 16000  # Most ML models prefer 16kHz\n",
    "        self.chunk_duration = 5  # Seconds of audio to transcribe at once\n",
    "        self.chunk_samples = self.target_sample_rate * self.chunk_duration\n",
    "        \n",
    "        # Get system default sample rate\n",
    "        self.system_sample_rate = sd.query_devices(kind='input')['default_samplerate']\n",
    "        print(f\"System Sample Rate: {self.system_sample_rate}\")\n",
    "        \n",
    "    def audio_callback(self, indata, frames, time, status):\n",
    "        \"\"\"\n",
    "        Callback function for processing audio stream\n",
    "        \n",
    "        :param indata: Input audio data\n",
    "        :param frames: Number of frames\n",
    "        :param time: Timestamp\n",
    "        :param status: Stream status\n",
    "        \"\"\"\n",
    "        if status:\n",
    "            print(f\"Stream error: {status}\")\n",
    "            return\n",
    "        \n",
    "        # Convert to numpy array and ensure mono\n",
    "        audio = indata.flatten()\n",
    "        \n",
    "        # Resample to 16kHz if needed\n",
    "        if self.system_sample_rate != self.target_sample_rate:\n",
    "            audio = self._resample(audio, self.system_sample_rate, self.target_sample_rate)\n",
    "        \n",
    "        # Prepare audio for model\n",
    "        input_features = self.processor(\n",
    "            audio, \n",
    "            sampling_rate=self.target_sample_rate, \n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features.to(device=self.device, dtype=self.torch_dtype)\n",
    "        \n",
    "        # Transcribe\n",
    "        with torch.no_grad():\n",
    "            predicted_ids = self.model.generate(input_features)\n",
    "            transcription = self.processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        print(f\"Transcription: {transcription}\")\n",
    "    \n",
    "    def _resample(self, audio, orig_sr, target_sr):\n",
    "        \"\"\"\n",
    "        Resample audio to target sample rate\n",
    "        \n",
    "        :param audio: Input audio array\n",
    "        :param orig_sr: Original sample rate\n",
    "        :param target_sr: Target sample rate\n",
    "        :return: Resampled audio\n",
    "        \"\"\"\n",
    "        # Calculate number of samples for resampling\n",
    "        duration = len(audio) / orig_sr\n",
    "        num_samples = int(duration * target_sr)\n",
    "        \n",
    "        # Use scipy's resample function\n",
    "        return resample(audio, num_samples)\n",
    "    \n",
    "    def start_transcription(self):\n",
    "        \"\"\"\n",
    "        Start live audio transcription with keyboard interrupt support\n",
    "        \"\"\"\n",
    "        print(f\"Starting transcription on {self.device}. Speak now...\")\n",
    "        print(\"Press Ctrl+C to stop transcription.\")\n",
    "        \n",
    "        try:\n",
    "            # Open audio stream\n",
    "            with sd.InputStream(\n",
    "                samplerate=self.system_sample_rate,\n",
    "                channels=1,  # Mono\n",
    "                dtype='float32',\n",
    "                callback=self.audio_callback,\n",
    "                blocksize=int(self.system_sample_rate * self.chunk_duration)\n",
    "            ):\n",
    "                # Keep the main thread running\n",
    "                while True:\n",
    "                    sd.sleep(1000)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nTranscription stopped by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using dtype: torch.float32\n",
      "System Sample Rate: 44100.0\n",
      "Starting transcription on cuda. Speak now...\n",
      "Press Ctrl+C to stop transcription.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  Hello, how was this going on?\n",
      "Transcription:  Hello, is the audio available?\n",
      "Transcription:  Is it live or is it good? Is it bad? How fast is it?\n",
      "Transcription:  it? Oh, until I speak it would not be possible to\n",
      "Transcription:  Don't give the transcription until I end it.\n",
      "Transcription:  Or does it have a length of time limit till which if I don't speak it won't give any line?\n",
      "Transcription:  Okay, okay, then what to do?\n",
      "Transcription:  I\n",
      "Transcription:  Hmm.\n",
      "Transcription:  चेरी अगे\n",
      "\n",
      "Transcription stopped by user.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    transcriber = LiveTranscriber()\n",
    "    transcriber.start_transcription()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
